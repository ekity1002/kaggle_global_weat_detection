{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWnPD5_9g6sx"
   },
   "source": [
    "# train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps '../input/timm_package/timm-0.1.26-py3-none-any.whl' > /dev/null\n",
    "!pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tov-32SKgSmu"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../input/timm_efficientdet_pytorch\")\n",
    "sys.path.insert(0, \"../input/omegaconf\")\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "\n",
    "SEED = 777\n",
    "N_SPLITS = 3\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "#marking = all_train_images.copy()\n",
    "marking = pd.read_csv('../input/marking.csv')\n",
    "marking = marking.rename(columns={'bbox_xmin': 'x', 'bbox_ymin': 'y', 'bbox_width': 'w', 'bbox_height': 'h'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147842\n",
      "147788\n"
     ]
    }
   ],
   "source": [
    "# データ整形\n",
    "## 面積の大きいbboxを削除\n",
    "def delete_bbox(df):\n",
    "    # でかいbbox, 面積0のbboxを除去\n",
    "    th=200000\n",
    "    df = df[(1 < df['bbox_area']) & (df['bbox_area'] < th)]\n",
    "    return df\n",
    "\n",
    "print(len(marking))\n",
    "marking = delete_bbox(marking)\n",
    "print(len(marking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marking.head()\n",
    "bin_edges = [0, 40, 120, 200]\n",
    "marking['brightness_bin'] = pd.cut(marking['brightness'], bin_edges, labels=False)\n",
    "#print(marking['brigntness_bin'].values.astype(str))\n",
    "#marking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzFMllwCg-sc"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=777)\n",
    "\n",
    "df_folds = marking[['image_id']].copy()\n",
    "df_folds.loc[:, 'bbox_count'] = 1\n",
    "df_folds = df_folds.groupby('image_id').count()\n",
    "df_folds.loc[:, 'source'] = marking[['image_id', 'source']].groupby('image_id').min()['source']\n",
    "df_folds.loc[:, 'brightness_bin'] = marking[['image_id', 'brightness_bin']].groupby('image_id').min()['brightness_bin']\n",
    "df_folds.loc[:, 'stratify_group'] = np.char.add(\n",
    "    df_folds['source'].values.astype(str),\n",
    "    #df_folds['brightness_bin'].values.astype(str),\n",
    "    df_folds['bbox_count'].apply(lambda x: f'_{x // 15}').values.astype(str)\n",
    ")\n",
    "df_folds.loc[:, 'fold'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "JGT_3PWGjYfM",
    "outputId": "980d9a4a-62ce-440b-c415-94e26eabd6f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox_count</th>\n",
       "      <th>source</th>\n",
       "      <th>brightness_bin</th>\n",
       "      <th>stratify_group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00333207f</th>\n",
       "      <td>55</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>2</td>\n",
       "      <td>arvalis_1_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005b0d8bb</th>\n",
       "      <td>20</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>1</td>\n",
       "      <td>usask_1_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006a994f7</th>\n",
       "      <td>25</td>\n",
       "      <td>inrae_1</td>\n",
       "      <td>1</td>\n",
       "      <td>inrae_1_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00764ad5d</th>\n",
       "      <td>41</td>\n",
       "      <td>inrae_1</td>\n",
       "      <td>1</td>\n",
       "      <td>inrae_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00b5fefed</th>\n",
       "      <td>25</td>\n",
       "      <td>arvalis_3</td>\n",
       "      <td>0</td>\n",
       "      <td>arvalis_3_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffb445410</th>\n",
       "      <td>57</td>\n",
       "      <td>rres_1</td>\n",
       "      <td>0</td>\n",
       "      <td>rres_1_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbf75e5b</th>\n",
       "      <td>52</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>1</td>\n",
       "      <td>arvalis_1_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbfe7cc0</th>\n",
       "      <td>34</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>1</td>\n",
       "      <td>arvalis_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc870198</th>\n",
       "      <td>41</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>1</td>\n",
       "      <td>usask_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffdf83e42</th>\n",
       "      <td>39</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>1</td>\n",
       "      <td>arvalis_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3373 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bbox_count     source  brightness_bin stratify_group  fold\n",
       "image_id                                                             \n",
       "00333207f          55  arvalis_1               2    arvalis_1_3     0\n",
       "005b0d8bb          20    usask_1               1      usask_1_1     0\n",
       "006a994f7          25    inrae_1               1      inrae_1_1     0\n",
       "00764ad5d          41    inrae_1               1      inrae_1_2     0\n",
       "00b5fefed          25  arvalis_3               0    arvalis_3_1     0\n",
       "...               ...        ...             ...            ...   ...\n",
       "ffb445410          57     rres_1               0       rres_1_3     0\n",
       "ffbf75e5b          52  arvalis_1               1    arvalis_1_3     0\n",
       "ffbfe7cc0          34  arvalis_1               1    arvalis_1_2     0\n",
       "ffc870198          41    usask_1               1      usask_1_2     0\n",
       "ffdf83e42          39  arvalis_1               1    arvalis_1_2     0\n",
       "\n",
       "[3373 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds.to_csv('df_folds.csv')\n",
    "df_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "rTQFS81QjMfR",
    "outputId": "5fc3b4b9-66c2-4695-c82f-9d04f8a07dad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for fold_number, (train_index, val_index) in enumerate(skf.split(X=df_folds.index, y=df_folds['stratify_group'])):\n",
    "    df_folds.loc[df_folds.iloc[val_index].index, 'fold'] = fold_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "or8mSwLNkeOt",
    "outputId": "1c6f11aa-055f-4865-92c6-798122baded8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox_count</th>\n",
       "      <th>source</th>\n",
       "      <th>brightness_bin</th>\n",
       "      <th>stratify_group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00333207f</th>\n",
       "      <td>55</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>2</td>\n",
       "      <td>arvalis_1_3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005b0d8bb</th>\n",
       "      <td>20</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>1</td>\n",
       "      <td>usask_1_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006a994f7</th>\n",
       "      <td>25</td>\n",
       "      <td>inrae_1</td>\n",
       "      <td>1</td>\n",
       "      <td>inrae_1_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00764ad5d</th>\n",
       "      <td>41</td>\n",
       "      <td>inrae_1</td>\n",
       "      <td>1</td>\n",
       "      <td>inrae_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00b5fefed</th>\n",
       "      <td>25</td>\n",
       "      <td>arvalis_3</td>\n",
       "      <td>0</td>\n",
       "      <td>arvalis_3_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bbox_count     source  brightness_bin stratify_group  fold\n",
       "image_id                                                             \n",
       "00333207f          55  arvalis_1               2    arvalis_1_3     2\n",
       "005b0d8bb          20    usask_1               1      usask_1_1     2\n",
       "006a994f7          25    inrae_1               1      inrae_1_1     1\n",
       "00764ad5d          41    inrae_1               1      inrae_1_2     0\n",
       "00b5fefed          25  arvalis_3               0    arvalis_3_1     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_folds['stratify_group'].value_counts()\n",
    "#df_folds[df_folds['stratify_group'] == '0_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkOxNMYdnVjm"
   },
   "source": [
    "# 水増し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_NP7F5bnUiU"
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.RandomSizedCrop(min_max_height=(800, 800), height=1024, width=1024, p=0.5),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                     val_shift_limit=0.2, p=0.9),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                           contrast_limit=0.2, p=0.9),\n",
    "                A.RandomGamma(),\n",
    "            ],p=0.9),\n",
    "            #A.CLAHE(p=1.0),\n",
    "            A.ToGray(p=0.01),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Resize(height=512, width=512, p=1),\n",
    "            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            #A.CLAHE(p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iozS5zbDneoR"
   },
   "outputs": [],
   "source": [
    "#test autmentation :TODO\n",
    "#apply_transforms(get_train_transforms(), all_train_images, n_transforms=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0Q0_3zJs0Ay"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ot8ULFtCsXEk"
   },
   "outputs": [],
   "source": [
    "TRAIN_ROOT_PATH = '../input/raw/train'\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, marking, image_ids, transforms=None, test=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = image_ids\n",
    "        self.marking = marking\n",
    "        self.transforms = transforms\n",
    "        self.test = test\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        \n",
    "        if self.test or random.random() > 0.5:\n",
    "            image, boxes = self.load_image_and_boxes(index)\n",
    "        else:\n",
    "            image, boxes = self.load_cutmix_image_and_boxes(index)\n",
    "#         else:\n",
    "#             image, boxes = self.load_mixup_image_and_boxes(index)\n",
    "\n",
    "        # there is only one class\n",
    "        labels = torch.ones((boxes.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "\n",
    "        if self.transforms:\n",
    "            for i in range(10):\n",
    "                sample = self.transforms(**{\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': labels\n",
    "                })\n",
    "                if len(sample['bboxes']) > 0:\n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
    "                    break\n",
    "\n",
    "        return image, target, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def load_image_and_boxes(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        records = self.marking[self.marking['image_id'] == image_id]\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        return image, boxes\n",
    "\n",
    "    def load_cutmix_image_and_boxes(self, index, imsize=1024):\n",
    "        \"\"\" \n",
    "        This implementation of cutmix author:  https://www.kaggle.com/nvnnghia \n",
    "        Refactoring and adaptation: https://www.kaggle.com/shonenkov\n",
    "        https://www.kaggle.com/shonenkov/oof-evaluation-mixup-efficientdet　のMixup #3に対応\n",
    "        \"\"\"\n",
    "\n",
    "        w, h = imsize, imsize\n",
    "        s = imsize // 2\n",
    "    \n",
    "        xc, yc = [int(random.uniform(imsize * 0.25, imsize * 0.75)) for _ in range(2)]  # center x, y\n",
    "        indexes = [index] + [random.randint(0, self.image_ids.shape[0] - 1) for _ in range(3)]\n",
    "\n",
    "        result_image = np.full((imsize, imsize, 3), 1, dtype=np.float32)\n",
    "        result_boxes = []\n",
    "\n",
    "        for i, index in enumerate(indexes):\n",
    "            image, boxes = self.load_image_and_boxes(index)\n",
    "            if i == 0:\n",
    "                x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n",
    "                x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n",
    "            elif i == 1:  # top right\n",
    "                x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n",
    "                x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n",
    "            elif i == 2:  # bottom left\n",
    "                x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n",
    "                x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n",
    "            elif i == 3:  # bottom right\n",
    "                x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n",
    "                x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n",
    "            result_image[y1a:y2a, x1a:x2a] = image[y1b:y2b, x1b:x2b]\n",
    "            padw = x1a - x1b\n",
    "            padh = y1a - y1b\n",
    "\n",
    "            boxes[:, 0] += padw\n",
    "            boxes[:, 1] += padh\n",
    "            boxes[:, 2] += padw\n",
    "            boxes[:, 3] += padh\n",
    "\n",
    "            result_boxes.append(boxes)\n",
    "\n",
    "        result_boxes = np.concatenate(result_boxes, 0)\n",
    "        np.clip(result_boxes[:, 0:], 0, 2 * s, out=result_boxes[:, 0:])\n",
    "        result_boxes = result_boxes.astype(np.int32)\n",
    "        result_boxes = result_boxes[np.where((result_boxes[:,2]-result_boxes[:,0])*(result_boxes[:,3]-result_boxes[:,1]) > 0)]\n",
    "        return result_image, result_boxes\n",
    "    \n",
    "    def load_mixup_image_and_boxes(self, index, imsize=1024):\n",
    "        result_boxes = []\n",
    "        image, boxes = self.load_image_and_boxes(index)\n",
    "        r_image, r_boxes = self.load_image_and_boxes(random.randint(0, self.image_ids.shape[0] - 1))\n",
    "        mixup_image = (image+r_image)/2\n",
    "\n",
    "        result_image = mixup_image.copy()\n",
    "        result_boxes.append(boxes)\n",
    "        result_boxes.append(r_boxes)\n",
    "        \n",
    "        return result_image, np.array(result_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vS6whXK5vSQl"
   },
   "source": [
    "# Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8P_vFwMm2qc"
   },
   "outputs": [],
   "source": [
    "#Fitter\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzOOqLPfvOrW"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'./{config.folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "        \n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_summary_loss = 10**5\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss = self.train_one_epoch(train_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            self.save(f'{self.base_dir}/last-checkpoint.bin')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss = self.validation(validation_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_summary_loss:\n",
    "                self.best_summary_loss = summary_loss.avg\n",
    "                self.model.eval()\n",
    "                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=summary_loss.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets, image_ids) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                images = torch.stack(images)\n",
    "                batch_size = images.shape[0]\n",
    "                images = images.to(self.device).float()\n",
    "                boxes = [target['boxes'].to(self.device).float() for target in targets]\n",
    "                labels = [target['labels'].to(self.device).float() for target in targets]\n",
    "\n",
    "                loss, _, _ = self.model(images, boxes, labels)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "        return summary_loss\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets, image_ids) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            \n",
    "            images = torch.stack(images)\n",
    "            images = images.to(self.device).float()\n",
    "            batch_size = images.shape[0]\n",
    "            boxes = [target['boxes'].to(self.device).float() for target in targets]\n",
    "            labels = [target['labels'].to(self.device).float() for target in targets]\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss, _, _ = self.model(images, boxes, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "        return summary_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_summary_loss': self.best_summary_loss,\n",
    "            'epoch': self.epoch,\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_summary_loss = checkpoint['best_summary_loss']\n",
    "        self.epoch = checkpoint['epoch'] + 1\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hORyLM9svQt0"
   },
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 8\n",
    "    batch_size = 4\n",
    "    n_epochs = 60\n",
    "    lr = 0.0002\n",
    "\n",
    "    folder = '../output/model/effdet7-cutmix-augmix'\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = True  # do scheduler.step after validation stage loss\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "#     scheduler_params = dict(\n",
    "#         max_lr=0.001,\n",
    "#         epochs=n_epochs,\n",
    "#         steps_per_epoch=int(len(train_dataset) / batch_size),\n",
    "#         pct_start=0.1,\n",
    "#         anneal_strategy='cos', \n",
    "#         final_div_factor=10**5\n",
    "#     )\n",
    "    \n",
    "#     SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "#     scheduler_params = dict(\n",
    "#         mode='min',\n",
    "#         factor=0.5,\n",
    "#         patience=2,\n",
    "#         verbose=False, \n",
    "#         threshold=0.0001,\n",
    "#         threshold_mode='abs',\n",
    "#         cooldown=0, \n",
    "#         min_lr=1e-8,\n",
    "#         eps=1e-08\n",
    "#     )\n",
    "    SchedulerClass = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "    scheduler_params = dict(\n",
    "        T_0=30,\n",
    "        T_mult=1,\n",
    "    )\n",
    "    # --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HyBcGkdFvqCL"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def run_training(net, train_dataset, val_dataset,):\n",
    "    device = torch.device('cuda:0')\n",
    "    net.to(device)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=RandomSampler(train_dataset),\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(val_dataset),\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "ORFFbzlNwHy2",
    "outputId": "79c91d1f-1bd6-4f80-d1d6-78ce532debea"
   },
   "outputs": [],
   "source": [
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "def get_net():\n",
    "    #config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    config = get_efficientdet_config('tf_efficientdet_d7')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    #checkpoint = torch.load('../input/efficientdet_pytorch/efficientdet_d5-ef44aea8.pth')\n",
    "    checkpoint = torch.load('../input/efficientdet_pytorch/efficientdet_d7-f05bf714.pth')\n",
    "    net.load_state_dict(checkpoint)\n",
    "    config.num_classes = 1\n",
    "    config.image_size = 512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "    return DetBenchTrain(net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image():\n",
    "    train_dataset = DatasetRetriever(\n",
    "    image_ids=df_folds[df_folds['fold'] != 0].index.values,\n",
    "    marking=marking,\n",
    "    transforms=get_train_transforms(),\n",
    "    test=False,\n",
    "    )\n",
    "\n",
    "    count = 4\n",
    "    for i in range(count):\n",
    "        image, boxes = train_dataset.load_mixup_image_and_boxes(random.randint(0, train_dataset.image_ids.shape[0] - 1))\n",
    "        print(image.shape)\n",
    "        plt.imshow(image)\n",
    "        for b in boxes:\n",
    "            for box in b.astype(int):\n",
    "                cv2.rectangle(image,(box[0], box[1]),(box[2],  box[3]),(0, 0, 1), 3)\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fold train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCII8uCtwlSd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0: train start\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-02T14:32:28.882420\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 0, summary_loss: 1.46112, time: 668.74503\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.47359, time: 86.31124\n",
      "\n",
      "2020-08-02T14:45:05.650126\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.49731, time: 665.46942\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.42861, time: 84.97093\n",
      "\n",
      "2020-08-02T14:57:42.618726\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.47017, time: 665.02935\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.40798, time: 84.78478\n",
      "\n",
      "2020-08-02T15:10:19.034808\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.45525, time: 664.86369\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.40878, time: 84.97601\n",
      "\n",
      "2020-08-02T15:22:54.507656\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.44357, time: 664.52223\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.39757, time: 85.08163\n",
      "\n",
      "2020-08-02T15:35:30.634533\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.44050, time: 664.37394\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.38775, time: 84.89743\n",
      "\n",
      "2020-08-02T15:48:06.592910\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.43507, time: 665.10846\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.39069, time: 85.13044\n",
      "\n",
      "2020-08-02T16:00:42.424286\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.43079, time: 665.22968\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.38546, time: 85.16635\n",
      "\n",
      "2020-08-02T16:13:26.613655\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.42644, time: 665.12211\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.38060, time: 84.84443\n",
      "\n",
      "2020-08-02T16:26:03.209582\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.42148, time: 665.04128\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.39240, time: 84.95038\n",
      "\n",
      "2020-08-02T16:38:38.770832\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.42288, time: 664.46780\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.38134, time: 84.76871\n",
      "\n",
      "2020-08-02T16:51:13.816801\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.41665, time: 663.94648\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.37956, time: 84.66054\n",
      "\n",
      "2020-08-02T17:03:49.098822\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.41832, time: 663.99594\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.38327, time: 84.79991\n",
      "\n",
      "2020-08-02T17:16:23.632389\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.41322, time: 664.32577\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.37853, time: 85.04557\n",
      "\n",
      "2020-08-02T17:28:59.483447\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.40945, time: 664.92113\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.38658, time: 84.93304\n",
      "\n",
      "2020-08-02T17:41:35.004422\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.40824, time: 664.85987\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.37788, time: 85.03273\n",
      "\n",
      "2020-08-02T17:54:11.531679\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.41034, time: 664.52559\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.37897, time: 85.00122\n",
      "\n",
      "2020-08-02T18:06:46.823646\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.40631, time: 665.58541\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.37154, time: 85.27211\n",
      "\n",
      "2020-08-02T18:19:24.391302\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.40455, time: 665.89199\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.37512, time: 84.96943\n",
      "\n",
      "2020-08-02T18:32:00.936357\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.40139, time: 665.17521\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.37254, time: 84.96792\n",
      "\n",
      "2020-08-02T18:44:37.055515\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.40004, time: 664.92967\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.37553, time: 84.91044\n",
      "\n",
      "2020-08-02T18:57:12.536814\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.39017, time: 664.45024\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.36266, time: 85.11508\n",
      "\n",
      "2020-08-02T19:09:48.733575\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.38718, time: 664.54339\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.36628, time: 84.97956\n",
      "\n",
      "2020-08-02T19:22:23.998563\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.38297, time: 665.04501\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.36713, time: 85.19302\n",
      "\n",
      "2020-08-02T19:34:59.833770\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.38138, time: 665.14442\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.36792, time: 84.93891\n",
      "\n",
      "2020-08-02T19:47:35.658414\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.37664, time: 665.00272\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.37337, time: 85.11806\n",
      "\n",
      "2020-08-02T20:00:11.498538\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.37334, time: 664.62550\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.36112, time: 85.66412\n",
      "\n",
      "2020-08-02T20:12:48.553582\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.37263, time: 668.13547\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.36062, time: 85.06100\n",
      "\n",
      "2020-08-02T20:25:28.354848\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.36875, time: 664.72493\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.36355, time: 84.92781\n",
      "\n",
      "2020-08-02T20:38:03.781480\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.36900, time: 663.66517\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.36618, time: 84.83533\n",
      "\n",
      "2020-08-02T20:50:38.042953\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 30, summary_loss: 0.36799, time: 663.68894\n",
      "[RESULT]: Val. Epoch: 30, summary_loss: 0.36509, time: 84.87362\n",
      "\n",
      "2020-08-02T21:03:12.326408\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 31, summary_loss: 0.36361, time: 663.54021\n",
      "[RESULT]: Val. Epoch: 31, summary_loss: 0.35916, time: 85.20645\n",
      "\n",
      "2020-08-02T21:15:47.697083\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 32, summary_loss: 0.36251, time: 663.86522\n",
      "[RESULT]: Val. Epoch: 32, summary_loss: 0.36215, time: 84.92890\n",
      "\n",
      "2020-08-02T21:28:22.215578\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 33, summary_loss: 0.36352, time: 663.32760\n",
      "[RESULT]: Val. Epoch: 33, summary_loss: 0.35995, time: 84.87803\n",
      "\n",
      "2020-08-02T21:40:56.332932\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 34, summary_loss: 0.36174, time: 663.71728\n",
      "[RESULT]: Val. Epoch: 34, summary_loss: 0.36362, time: 84.82930\n",
      "\n",
      "2020-08-02T21:53:30.657043\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 35, summary_loss: 0.35855, time: 663.27883\n",
      "[RESULT]: Val. Epoch: 35, summary_loss: 0.36225, time: 85.11195\n",
      "\n",
      "2020-08-02T22:06:04.739294\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 36, summary_loss: 0.35869, time: 662.47445\n",
      "[RESULT]: Val. Epoch: 36, summary_loss: 0.36074, time: 84.63393\n",
      "\n",
      "2020-08-02T22:18:37.543890\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 37, summary_loss: 0.35708, time: 662.27446\n",
      "[RESULT]: Val. Epoch: 37, summary_loss: 0.36406, time: 84.80231\n",
      "\n",
      "2020-08-02T22:31:10.360916\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 38, summary_loss: 0.35840, time: 662.02958\n",
      "[RESULT]: Val. Epoch: 38, summary_loss: 0.36063, time: 84.55497\n",
      "\n",
      "2020-08-02T22:43:42.687801\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 39, summary_loss: 0.35665, time: 661.07178\n",
      "[RESULT]: Val. Epoch: 39, summary_loss: 0.35958, time: 84.50297\n",
      "\n",
      "2020-08-02T22:56:13.956479\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 40, summary_loss: 0.35744, time: 660.89003\n",
      "[RESULT]: Val. Epoch: 40, summary_loss: 0.36346, time: 84.58526\n",
      "\n",
      "2020-08-02T23:08:45.200737\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 41, summary_loss: 0.35282, time: 661.23773\n",
      "[RESULT]: Val. Epoch: 41, summary_loss: 0.35832, time: 84.59753\n",
      "\n",
      "2020-08-02T23:21:17.706905\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 42, summary_loss: 0.35385, time: 661.06674\n",
      "[RESULT]: Val. Epoch: 42, summary_loss: 0.35931, time: 84.69971\n",
      "\n",
      "2020-08-02T23:33:49.341101\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 43, summary_loss: 0.35596, time: 661.35530\n",
      "[RESULT]: Val. Epoch: 43, summary_loss: 0.36228, time: 84.64953\n",
      "\n",
      "2020-08-02T23:46:21.044508\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 44, summary_loss: 0.35312, time: 661.10379\n",
      "[RESULT]: Val. Epoch: 44, summary_loss: 0.36023, time: 84.60576\n",
      "\n",
      "2020-08-02T23:58:52.381259\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 45, summary_loss: 0.35826, time: 661.76747\n",
      "[RESULT]: Val. Epoch: 45, summary_loss: 0.36181, time: 84.53517\n",
      "\n",
      "2020-08-03T00:11:24.360040\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 46, summary_loss: 0.35741, time: 661.15409\n",
      "[RESULT]: Val. Epoch: 46, summary_loss: 0.36011, time: 84.74025\n",
      "\n",
      "2020-08-03T00:23:55.964594\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 47, summary_loss: 0.35770, time: 661.38599\n",
      "[RESULT]: Val. Epoch: 47, summary_loss: 0.36356, time: 84.57707\n",
      "\n",
      "2020-08-03T00:36:27.631045\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 48, summary_loss: 0.35529, time: 661.58439\n",
      "[RESULT]: Val. Epoch: 48, summary_loss: 0.35962, time: 84.69361\n",
      "\n",
      "2020-08-03T00:48:59.597441\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 49, summary_loss: 0.35456, time: 661.67036\n",
      "[RESULT]: Val. Epoch: 49, summary_loss: 0.36130, time: 84.51317\n",
      "\n",
      "2020-08-03T01:01:31.595421\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 50, summary_loss: 0.35793, time: 661.48272\n",
      "[RESULT]: Val. Epoch: 50, summary_loss: 0.36081, time: 84.54093\n",
      "\n",
      "2020-08-03T01:14:03.327742\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 51, summary_loss: 0.35426, time: 661.22696\n",
      "[RESULT]: Val. Epoch: 51, summary_loss: 0.35905, time: 84.58802\n",
      "\n",
      "2020-08-03T01:26:34.977877\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 52, summary_loss: 0.35543, time: 661.43573\n",
      "[RESULT]: Val. Epoch: 52, summary_loss: 0.37114, time: 84.52838\n",
      "\n",
      "2020-08-03T01:39:06.510783\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 53, summary_loss: 0.35625, time: 661.38845\n",
      "[RESULT]: Val. Epoch: 53, summary_loss: 0.36093, time: 84.62535\n",
      "\n",
      "2020-08-03T01:51:38.311068\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 54, summary_loss: 0.35353, time: 661.08212\n",
      "[RESULT]: Val. Epoch: 54, summary_loss: 0.35913, time: 84.62548\n",
      "\n",
      "2020-08-03T02:04:09.709284\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 55, summary_loss: 0.35720, time: 661.84314\n",
      "[RESULT]: Val. Epoch: 55, summary_loss: 0.36224, time: 84.65806\n",
      "\n",
      "2020-08-03T02:16:41.813222\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 56, summary_loss: 0.35502, time: 661.73043\n",
      "[RESULT]: Val. Epoch: 56, summary_loss: 0.36215, time: 84.49307\n",
      "\n",
      "2020-08-03T02:29:13.816804\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 57, summary_loss: 0.35430, time: 661.40782\n",
      "[RESULT]: Val. Epoch: 57, summary_loss: 0.35969, time: 84.55234\n",
      "\n",
      "2020-08-03T02:41:45.506019\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 58, summary_loss: 0.35750, time: 661.43319\n",
      "[RESULT]: Val. Epoch: 58, summary_loss: 0.35929, time: 84.49244\n",
      "\n",
      "2020-08-03T02:54:17.249205\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 59, summary_loss: 0.35628, time: 661.33756\n",
      "[RESULT]: Val. Epoch: 59, summary_loss: 0.36271, time: 84.47113\n",
      "fold1: train start\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-03T03:06:50.876394\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 0, summary_loss: 1.50777, time: 663.58071\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.48515, time: 84.39248\n",
      "\n",
      "2020-08-03T03:19:20.568464\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.49888, time: 661.85495\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.41462, time: 84.58534\n",
      "\n",
      "2020-08-03T03:31:53.596598\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.47261, time: 661.46224\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.40731, time: 84.39276\n",
      "\n",
      "2020-08-03T03:44:25.913533\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.45743, time: 661.90114\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.41719, time: 84.49146\n",
      "\n",
      "2020-08-03T03:56:58.081612\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.44908, time: 661.70460\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.40986, time: 84.61799\n",
      "\n",
      "2020-08-03T04:09:30.034541\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.44388, time: 661.69156\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.39538, time: 84.64046\n",
      "\n",
      "2020-08-03T04:22:02.879080\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.43492, time: 661.92788\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.38502, time: 84.36814\n",
      "\n",
      "2020-08-03T04:34:35.759668\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.43023, time: 661.46061\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.38199, time: 84.41434\n",
      "\n",
      "2020-08-03T04:47:08.114698\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.43050, time: 661.65445\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.41729, time: 84.51482\n",
      "\n",
      "2020-08-03T04:59:40.000340\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.42320, time: 661.49987\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.37893, time: 84.65567\n",
      "\n",
      "2020-08-03T05:12:12.665129\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.42105, time: 661.50009\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.38590, time: 84.51645\n",
      "\n",
      "2020-08-03T05:24:44.408990\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.41618, time: 662.01717\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.38703, time: 84.49929\n",
      "\n",
      "2020-08-03T05:37:16.589708\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.41892, time: 661.66013\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.37839, time: 84.54172\n",
      "\n",
      "2020-08-03T05:49:49.271133\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.41465, time: 661.83866\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.38095, time: 84.43508\n",
      "\n",
      "2020-08-03T06:02:21.331266\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.41402, time: 661.51742\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.38119, time: 84.39234\n",
      "\n",
      "2020-08-03T06:14:52.978096\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.41039, time: 661.95890\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.37490, time: 84.63229\n",
      "\n",
      "2020-08-03T06:27:26.357319\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.40876, time: 662.07803\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.37705, time: 84.46273\n",
      "\n",
      "2020-08-03T06:39:58.779280\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.40700, time: 661.40905\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.37862, time: 84.57156\n",
      "\n",
      "2020-08-03T06:52:30.466958\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.40859, time: 661.93343\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.37713, time: 84.48172\n",
      "\n",
      "2020-08-03T07:05:02.714620\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.39180, time: 662.06853\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.36655, time: 84.55667\n",
      "\n",
      "2020-08-03T07:17:35.998506\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.39028, time: 661.53266\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.36066, time: 84.39024\n",
      "\n",
      "2020-08-03T07:30:08.625730\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.39087, time: 661.48622\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.36512, time: 84.45213\n",
      "\n",
      "2020-08-03T07:42:40.340481\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.38827, time: 661.46968\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.36433, time: 84.40324\n",
      "\n",
      "2020-08-03T07:55:12.071002\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.38418, time: 661.93703\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.36614, time: 84.42000\n",
      "\n",
      "2020-08-03T08:07:44.037723\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.37832, time: 661.77188\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.35912, time: 84.54420\n",
      "\n",
      "2020-08-03T08:20:16.977155\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.37466, time: 664.48573\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.36025, time: 84.58604\n",
      "\n",
      "2020-08-03T08:32:51.811643\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.37608, time: 663.26744\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.35780, time: 84.63319\n",
      "\n",
      "2020-08-03T08:45:26.281831\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.37332, time: 663.57007\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.35850, time: 84.79421\n",
      "\n",
      "2020-08-03T08:58:00.250019\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.37129, time: 663.43321\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.35714, time: 84.59485\n",
      "\n",
      "2020-08-03T09:10:34.918152\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.37101, time: 664.34823\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.36469, time: 84.79579\n",
      "\n",
      "2020-08-03T09:23:09.806518\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 30, summary_loss: 0.36918, time: 664.66171\n",
      "[RESULT]: Val. Epoch: 30, summary_loss: 0.36710, time: 84.74627\n",
      "\n",
      "2020-08-03T09:35:45.040209\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 31, summary_loss: 0.36743, time: 664.04796\n",
      "[RESULT]: Val. Epoch: 31, summary_loss: 0.36345, time: 84.55133\n",
      "\n",
      "2020-08-03T09:48:19.349254\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 32, summary_loss: 0.36396, time: 663.30910\n",
      "[RESULT]: Val. Epoch: 32, summary_loss: 0.35964, time: 84.71064\n",
      "\n",
      "2020-08-03T10:00:53.156612\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 33, summary_loss: 0.36166, time: 662.61005\n",
      "[RESULT]: Val. Epoch: 33, summary_loss: 0.36699, time: 84.42744\n",
      "\n",
      "2020-08-03T10:13:25.926030\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 34, summary_loss: 0.36176, time: 661.79884\n",
      "[RESULT]: Val. Epoch: 34, summary_loss: 0.36197, time: 84.59614\n",
      "\n",
      "2020-08-03T10:25:58.089034\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 35, summary_loss: 0.36309, time: 661.83851\n",
      "[RESULT]: Val. Epoch: 35, summary_loss: 0.36238, time: 84.60990\n",
      "\n",
      "2020-08-03T10:38:30.212051\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 36, summary_loss: 0.35881, time: 662.33354\n",
      "[RESULT]: Val. Epoch: 36, summary_loss: 0.36027, time: 84.39779\n",
      "\n",
      "2020-08-03T10:51:02.663226\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 37, summary_loss: 0.35907, time: 661.98261\n",
      "[RESULT]: Val. Epoch: 37, summary_loss: 0.35815, time: 84.45291\n",
      "\n",
      "2020-08-03T11:03:34.812602\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 38, summary_loss: 0.35892, time: 661.98655\n",
      "[RESULT]: Val. Epoch: 38, summary_loss: 0.36124, time: 84.44329\n",
      "\n",
      "2020-08-03T11:16:02.043262\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 39, summary_loss: 0.35511, time: 661.86090\n",
      "[RESULT]: Val. Epoch: 39, summary_loss: 0.35721, time: 84.58979\n",
      "\n",
      "2020-08-03T11:28:34.178353\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 40, summary_loss: 0.35591, time: 661.25481\n",
      "[RESULT]: Val. Epoch: 40, summary_loss: 0.36610, time: 84.50886\n",
      "\n",
      "2020-08-03T11:41:05.605402\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 41, summary_loss: 0.35443, time: 661.42320\n",
      "[RESULT]: Val. Epoch: 41, summary_loss: 0.36077, time: 84.45574\n",
      "\n",
      "2020-08-03T11:53:37.048202\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 42, summary_loss: 0.35741, time: 661.11077\n",
      "[RESULT]: Val. Epoch: 42, summary_loss: 0.35872, time: 84.49356\n",
      "\n",
      "2020-08-03T12:06:08.346752\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 43, summary_loss: 0.35734, time: 661.42973\n",
      "[RESULT]: Val. Epoch: 43, summary_loss: 0.35872, time: 84.30155\n",
      "\n",
      "2020-08-03T12:18:39.711163\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 44, summary_loss: 0.35711, time: 661.22396\n",
      "[RESULT]: Val. Epoch: 44, summary_loss: 0.36083, time: 84.33067\n",
      "\n",
      "2020-08-03T12:31:11.009195\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 45, summary_loss: 0.35616, time: 661.05003\n",
      "[RESULT]: Val. Epoch: 45, summary_loss: 0.36214, time: 84.46720\n",
      "\n",
      "2020-08-03T12:43:42.181711\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 46, summary_loss: 0.35760, time: 661.38318\n",
      "[RESULT]: Val. Epoch: 46, summary_loss: 0.36126, time: 84.40813\n",
      "\n",
      "2020-08-03T12:56:13.787178\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 47, summary_loss: 0.35559, time: 661.24662\n",
      "[RESULT]: Val. Epoch: 47, summary_loss: 0.35812, time: 84.33595\n",
      "\n",
      "2020-08-03T13:08:45.051074\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 48, summary_loss: 0.35352, time: 661.29161\n",
      "[RESULT]: Val. Epoch: 48, summary_loss: 0.36134, time: 84.55704\n",
      "\n",
      "2020-08-03T13:21:16.535495\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 49, summary_loss: 0.35819, time: 661.13522\n",
      "[RESULT]: Val. Epoch: 49, summary_loss: 0.36348, time: 84.36737\n",
      "\n",
      "2020-08-03T13:33:47.688194\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 50, summary_loss: 0.35596, time: 661.37402\n",
      "[RESULT]: Val. Epoch: 50, summary_loss: 0.35995, time: 84.41373\n",
      "\n",
      "2020-08-03T13:46:19.051339\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 51, summary_loss: 0.35430, time: 661.37988\n",
      "[RESULT]: Val. Epoch: 51, summary_loss: 0.36052, time: 84.32445\n",
      "\n",
      "2020-08-03T13:58:50.417990\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 52, summary_loss: 0.35569, time: 661.32317\n",
      "[RESULT]: Val. Epoch: 52, summary_loss: 0.36106, time: 84.43669\n",
      "\n",
      "2020-08-03T14:11:21.862860\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 53, summary_loss: 0.35519, time: 661.34834\n",
      "[RESULT]: Val. Epoch: 53, summary_loss: 0.35889, time: 84.33798\n",
      "\n",
      "2020-08-03T14:23:53.294658\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 54, summary_loss: 0.35651, time: 662.32627\n",
      "[RESULT]: Val. Epoch: 54, summary_loss: 0.36096, time: 84.43832\n",
      "\n",
      "2020-08-03T14:36:25.723151\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 55, summary_loss: 0.35230, time: 661.90463\n",
      "[RESULT]: Val. Epoch: 55, summary_loss: 0.36009, time: 84.59169\n",
      "\n",
      "2020-08-03T14:48:57.871393\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 56, summary_loss: 0.35510, time: 661.65023\n",
      "[RESULT]: Val. Epoch: 56, summary_loss: 0.35931, time: 84.39726\n",
      "\n",
      "2020-08-03T15:01:29.568738\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 57, summary_loss: 0.35468, time: 662.08485\n",
      "[RESULT]: Val. Epoch: 57, summary_loss: 0.35893, time: 84.43471\n",
      "\n",
      "2020-08-03T15:14:01.755082\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 58, summary_loss: 0.35682, time: 661.56596\n",
      "[RESULT]: Val. Epoch: 58, summary_loss: 0.35890, time: 84.50078\n",
      "\n",
      "2020-08-03T15:26:33.635006\n",
      "LR: 4.8828125e-08\n",
      "[RESULT]: Train. Epoch: 59, summary_loss: 0.35426, time: 663.08015\n",
      "[RESULT]: Val. Epoch: 59, summary_loss: 0.35800, time: 84.79876\n",
      "fold2: train start\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-03T15:39:09.245063\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 0, summary_loss: 1.48788, time: 663.03679\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.46623, time: 84.72108\n",
      "\n",
      "2020-08-03T15:51:38.732322\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.49438, time: 663.00476\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.43552, time: 84.86564\n",
      "\n",
      "2020-08-03T16:04:13.114379\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.46811, time: 662.65132\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.39878, time: 84.67832\n",
      "\n",
      "2020-08-03T16:16:46.997132\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.45262, time: 663.23304\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.39953, time: 84.55833\n",
      "\n",
      "2020-08-03T16:29:20.597523\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.44520, time: 663.02737\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.38643, time: 84.64750\n",
      "\n",
      "2020-08-03T16:41:54.768466\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.43731, time: 663.05927\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.40620, time: 84.74350\n",
      "\n",
      "2020-08-03T16:54:28.318903\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.43491, time: 663.82298\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.38946, time: 85.39104\n",
      "\n",
      "2020-08-03T17:07:03.178226\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.42947, time: 663.92436\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.38070, time: 84.80397\n",
      "\n",
      "2020-08-03T17:19:38.400813\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.42268, time: 667.11448\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.37978, time: 85.52413\n",
      "\n",
      "2020-08-03T17:32:17.797504\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.42563, time: 664.33910\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.37924, time: 84.89292\n",
      "\n",
      "2020-08-03T17:44:53.538882\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.42286, time: 664.53828\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.37603, time: 84.71129\n",
      "\n",
      "2020-08-03T17:57:29.320146\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.41934, time: 662.87546\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.37886, time: 84.69039\n",
      "\n",
      "2020-08-03T18:10:02.489460\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.41675, time: 663.51696\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.38943, time: 84.75138\n",
      "\n",
      "2020-08-03T18:22:36.512650\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.41270, time: 663.22777\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.37480, time: 84.83057\n",
      "\n",
      "2020-08-03T18:35:11.105742\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.41136, time: 665.63317\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.38416, time: 84.68792\n",
      "\n",
      "2020-08-03T18:47:47.240202\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.40851, time: 662.60846\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.37358, time: 84.78973\n",
      "\n",
      "2020-08-03T19:00:21.330923\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.40994, time: 662.42701\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.37528, time: 84.67073\n",
      "\n",
      "2020-08-03T19:12:54.150019\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.40652, time: 663.02937\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.37598, time: 84.67372\n",
      "\n",
      "2020-08-03T19:25:27.530830\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.40406, time: 664.40919\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.37116, time: 85.46961\n",
      "\n",
      "2020-08-03T19:38:04.031383\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.40438, time: 664.12947\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.39623, time: 84.75610\n",
      "\n",
      "2020-08-03T19:50:38.717928\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.40042, time: 663.19416\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.37786, time: 84.74229\n",
      "\n",
      "2020-08-03T20:03:12.385623\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.39983, time: 663.18000\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.37343, time: 84.75247\n",
      "\n",
      "2020-08-03T20:15:45.980914\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.38650, time: 662.77320\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.36771, time: 84.90554\n",
      "\n",
      "2020-08-03T20:28:20.342836\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.38357, time: 664.11378\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.36670, time: 84.72328\n",
      "\n",
      "2020-08-03T20:40:55.816751\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.37893, time: 667.88179\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.36116, time: 84.97954\n",
      "\n",
      "2020-08-03T20:53:35.380527\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.38100, time: 663.72303\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.36080, time: 84.91635\n",
      "\n",
      "2020-08-03T21:06:10.557017\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.37891, time: 664.91453\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.36058, time: 84.95108\n",
      "\n",
      "2020-08-03T21:18:47.111660\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.37855, time: 662.77703\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.36613, time: 84.81427\n",
      "\n",
      "2020-08-03T21:31:20.460299\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.37592, time: 665.75495\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.36622, time: 84.77567\n",
      "\n",
      "2020-08-03T21:43:56.638545\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.37902, time: 665.26189\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.36288, time: 85.51257\n",
      "\n",
      "2020-08-03T21:56:33.061473\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 30, summary_loss: 0.36964, time: 664.58268\n",
      "[RESULT]: Val. Epoch: 30, summary_loss: 0.35844, time: 84.71521\n",
      "\n",
      "2020-08-03T22:09:08.909676\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 31, summary_loss: 0.36565, time: 663.23467\n",
      "[RESULT]: Val. Epoch: 31, summary_loss: 0.35968, time: 84.76134\n",
      "\n",
      "2020-08-03T22:21:42.627681\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 32, summary_loss: 0.36439, time: 663.73310\n",
      "[RESULT]: Val. Epoch: 32, summary_loss: 0.36034, time: 85.38200\n",
      "\n",
      "2020-08-03T22:34:17.456302\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 33, summary_loss: 0.36433, time: 664.89641\n",
      "[RESULT]: Val. Epoch: 33, summary_loss: 0.36461, time: 84.90122\n",
      "\n",
      "2020-08-03T22:46:52.892336\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 34, summary_loss: 0.35947, time: 663.44255\n",
      "[RESULT]: Val. Epoch: 34, summary_loss: 0.36075, time: 84.77645\n",
      "\n",
      "2020-08-03T22:59:26.851126\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 35, summary_loss: 0.35861, time: 665.87188\n",
      "[RESULT]: Val. Epoch: 35, summary_loss: 0.35910, time: 84.68772\n",
      "\n",
      "2020-08-03T23:12:03.044603\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 36, summary_loss: 0.36095, time: 663.21202\n",
      "[RESULT]: Val. Epoch: 36, summary_loss: 0.35874, time: 84.80626\n",
      "\n",
      "2020-08-03T23:24:36.790776\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 37, summary_loss: 0.35502, time: 663.06872\n",
      "[RESULT]: Val. Epoch: 37, summary_loss: 0.35845, time: 84.78860\n",
      "\n",
      "2020-08-03T23:37:10.274984\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 38, summary_loss: 0.35645, time: 665.21463\n",
      "[RESULT]: Val. Epoch: 38, summary_loss: 0.35918, time: 85.14277\n",
      "\n",
      "2020-08-03T23:49:46.449565\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 39, summary_loss: 0.35403, time: 663.55268\n",
      "[RESULT]: Val. Epoch: 39, summary_loss: 0.35810, time: 84.61238\n",
      "\n",
      "2020-08-04T00:02:21.109719\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 40, summary_loss: 0.35284, time: 665.06214\n",
      "[RESULT]: Val. Epoch: 40, summary_loss: 0.35943, time: 85.09958\n",
      "\n",
      "2020-08-04T00:14:57.098366\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 41, summary_loss: 0.35594, time: 662.86761\n",
      "[RESULT]: Val. Epoch: 41, summary_loss: 0.35971, time: 84.50564\n",
      "\n",
      "2020-08-04T00:27:30.166225\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 42, summary_loss: 0.35221, time: 663.10538\n",
      "[RESULT]: Val. Epoch: 42, summary_loss: 0.35989, time: 84.69371\n",
      "\n",
      "2020-08-04T00:40:03.726330\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 43, summary_loss: 0.35274, time: 664.01685\n",
      "[RESULT]: Val. Epoch: 43, summary_loss: 0.35838, time: 85.39569\n",
      "\n",
      "2020-08-04T00:52:38.825967\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 44, summary_loss: 0.35438, time: 665.58986\n",
      "[RESULT]: Val. Epoch: 44, summary_loss: 0.35741, time: 84.97844\n",
      "\n",
      "2020-08-04T01:05:15.881195\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 45, summary_loss: 0.35122, time: 664.68144\n",
      "[RESULT]: Val. Epoch: 45, summary_loss: 0.35733, time: 85.29462\n",
      "\n",
      "2020-08-04T01:17:52.524249\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 46, summary_loss: 0.35134, time: 664.96668\n",
      "[RESULT]: Val. Epoch: 46, summary_loss: 0.35806, time: 84.83131\n",
      "\n",
      "2020-08-04T01:30:28.053147\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 47, summary_loss: 0.35068, time: 663.72304\n",
      "[RESULT]: Val. Epoch: 47, summary_loss: 0.35822, time: 84.72235\n",
      "\n",
      "2020-08-04T01:43:02.130162\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 48, summary_loss: 0.34961, time: 664.20259\n",
      "[RESULT]: Val. Epoch: 48, summary_loss: 0.35938, time: 85.41735\n",
      "\n",
      "2020-08-04T01:55:37.671905\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 49, summary_loss: 0.34957, time: 666.16704\n",
      "[RESULT]: Val. Epoch: 49, summary_loss: 0.35870, time: 85.13633\n",
      "\n",
      "2020-08-04T02:08:14.630630\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 50, summary_loss: 0.35053, time: 666.73315\n",
      "[RESULT]: Val. Epoch: 50, summary_loss: 0.35828, time: 84.89097\n",
      "\n",
      "2020-08-04T02:20:51.919496\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 51, summary_loss: 0.34888, time: 664.90217\n",
      "[RESULT]: Val. Epoch: 51, summary_loss: 0.35846, time: 85.04951\n",
      "\n",
      "2020-08-04T02:33:27.537786\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 52, summary_loss: 0.35349, time: 665.10441\n",
      "[RESULT]: Val. Epoch: 52, summary_loss: 0.35901, time: 84.88405\n",
      "\n",
      "2020-08-04T02:46:03.284616\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 53, summary_loss: 0.34831, time: 667.61998\n",
      "[RESULT]: Val. Epoch: 53, summary_loss: 0.35806, time: 85.53618\n",
      "\n",
      "2020-08-04T02:58:42.206457\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 54, summary_loss: 0.34975, time: 663.58033\n",
      "[RESULT]: Val. Epoch: 54, summary_loss: 0.35805, time: 84.85980\n",
      "\n",
      "2020-08-04T03:11:16.278859\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 55, summary_loss: 0.34968, time: 664.54785\n",
      "[RESULT]: Val. Epoch: 55, summary_loss: 0.35835, time: 85.59138\n",
      "\n",
      "2020-08-04T03:23:52.362032\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 56, summary_loss: 0.34881, time: 664.07268\n",
      "[RESULT]: Val. Epoch: 56, summary_loss: 0.35916, time: 84.71808\n",
      "\n",
      "2020-08-04T03:36:26.775680\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 57, summary_loss: 0.35149, time: 662.71812\n",
      "[RESULT]: Val. Epoch: 57, summary_loss: 0.35786, time: 84.84662\n",
      "\n",
      "2020-08-04T03:49:00.097320\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 58, summary_loss: 0.35071, time: 663.75789\n",
      "[RESULT]: Val. Epoch: 58, summary_loss: 0.35762, time: 84.79167\n",
      "\n",
      "2020-08-04T04:01:34.343425\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 59, summary_loss: 0.35237, time: 663.99828\n",
      "Val Step 108/281, summary_loss: 0.35859, time: 33.10895\r"
     ]
    }
   ],
   "source": [
    "for fold_number in range(N_SPLITS):\n",
    "    print(f'fold{fold_number}: train start')\n",
    "    \n",
    "    train_dataset = DatasetRetriever(\n",
    "        image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n",
    "        marking=marking,\n",
    "        transforms=get_train_transforms(),\n",
    "        test=False,\n",
    "    )\n",
    "    val_dataset = DatasetRetriever(\n",
    "        image_ids=df_folds[df_folds['fold'] == fold_number].index.values,\n",
    "        marking=marking,\n",
    "        transforms=get_valid_transforms(),\n",
    "        test=True,\n",
    "    )\n",
    "    # train model\n",
    "    net = get_net()\n",
    "    TrainGlobalConfig.folder = f'../output/model/effdet7-cutmix-augmix/fold{fold_number}'\n",
    "    run_training(net, train_dataset, val_dataset)\n",
    "\n",
    "#     image, target, image_id = train_dataset[1]\n",
    "#     boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
    "\n",
    "#     numpy_image = image.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "#     for box in boxes:\n",
    "#         cv2.rectangle(numpy_image, (box[1], box[0]), (box[3],  box[2]), (0, 1, 0), 2)\n",
    "\n",
    "#     ax.set_axis_off()\n",
    "#     ax.imshow(numpy_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GlobalWheatDetection EDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
