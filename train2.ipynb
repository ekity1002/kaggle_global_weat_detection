{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dWnPD5_9g6sx"
   },
   "source": [
    "# train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps '../input/timm_package/timm-0.1.26-py3-none-any.whl' > /dev/null\n",
    "!pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tov-32SKgSmu"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../input/timm_efficientdet_pytorch\")\n",
    "sys.path.insert(0, \"../input/omegaconf\")\n",
    "\n",
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from glob import glob\n",
    "\n",
    "SEED = 777\n",
    "N_SPLITS = 5\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "#marking = all_train_images.copy()\n",
    "marking = pd.read_csv('../input/marking.csv')\n",
    "marking = marking.rename(columns={'bbox_xmin': 'x', 'bbox_ymin': 'y', 'bbox_width': 'w', 'bbox_height': 'h'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147842\n",
      "147788\n"
     ]
    }
   ],
   "source": [
    "# データ整形\n",
    "## 面積の大きいbboxを削除\n",
    "def delete_bbox(df):\n",
    "    # でかいbbox, 面積0のbboxを除去\n",
    "    th=200000\n",
    "    df = df[(1 < df['bbox_area']) & (df['bbox_area'] < th)]\n",
    "    return df\n",
    "\n",
    "print(len(marking))\n",
    "marking = delete_bbox(marking)\n",
    "print(len(marking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marking.head()\n",
    "bin_edges = [0, 40, 120, 200]\n",
    "marking['brightness_bin'] = pd.cut(marking['brightness'], bin_edges, labels=False)\n",
    "#print(marking['brigntness_bin'].values.astype(str))\n",
    "#marking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzFMllwCg-sc"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=777)\n",
    "\n",
    "df_folds = marking[['image_id']].copy()\n",
    "df_folds.loc[:, 'bbox_count'] = 1\n",
    "df_folds = df_folds.groupby('image_id').count()\n",
    "df_folds.loc[:, 'source'] = marking[['image_id', 'source']].groupby('image_id').min()['source']\n",
    "df_folds.loc[:, 'brightness_bin'] = marking[['image_id', 'brightness_bin']].groupby('image_id').min()['brightness_bin']\n",
    "df_folds.loc[:, 'stratify_group'] = np.char.add(\n",
    "    df_folds['source'].values.astype(str),\n",
    "    #df_folds['brightness_bin'].values.astype(str),\n",
    "    df_folds['bbox_count'].apply(lambda x: f'_{x // 15}').values.astype(str)\n",
    ")\n",
    "df_folds.loc[:, 'fold'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "JGT_3PWGjYfM",
    "outputId": "980d9a4a-62ce-440b-c415-94e26eabd6f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox_count</th>\n",
       "      <th>source</th>\n",
       "      <th>brightness_bin</th>\n",
       "      <th>stratify_group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00333207f</th>\n",
       "      <td>55</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>2</td>\n",
       "      <td>arvalis_1_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005b0d8bb</th>\n",
       "      <td>20</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>1</td>\n",
       "      <td>usask_1_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006a994f7</th>\n",
       "      <td>25</td>\n",
       "      <td>inrae_1</td>\n",
       "      <td>1</td>\n",
       "      <td>inrae_1_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00764ad5d</th>\n",
       "      <td>41</td>\n",
       "      <td>inrae_1</td>\n",
       "      <td>1</td>\n",
       "      <td>inrae_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00b5fefed</th>\n",
       "      <td>25</td>\n",
       "      <td>arvalis_3</td>\n",
       "      <td>0</td>\n",
       "      <td>arvalis_3_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffb445410</th>\n",
       "      <td>57</td>\n",
       "      <td>rres_1</td>\n",
       "      <td>0</td>\n",
       "      <td>rres_1_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbf75e5b</th>\n",
       "      <td>52</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>1</td>\n",
       "      <td>arvalis_1_3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbfe7cc0</th>\n",
       "      <td>34</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>1</td>\n",
       "      <td>arvalis_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc870198</th>\n",
       "      <td>41</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>1</td>\n",
       "      <td>usask_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffdf83e42</th>\n",
       "      <td>39</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>1</td>\n",
       "      <td>arvalis_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3373 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bbox_count     source  brightness_bin stratify_group  fold\n",
       "image_id                                                             \n",
       "00333207f          55  arvalis_1               2    arvalis_1_3     0\n",
       "005b0d8bb          20    usask_1               1      usask_1_1     0\n",
       "006a994f7          25    inrae_1               1      inrae_1_1     0\n",
       "00764ad5d          41    inrae_1               1      inrae_1_2     0\n",
       "00b5fefed          25  arvalis_3               0    arvalis_3_1     0\n",
       "...               ...        ...             ...            ...   ...\n",
       "ffb445410          57     rres_1               0       rres_1_3     0\n",
       "ffbf75e5b          52  arvalis_1               1    arvalis_1_3     0\n",
       "ffbfe7cc0          34  arvalis_1               1    arvalis_1_2     0\n",
       "ffc870198          41    usask_1               1      usask_1_2     0\n",
       "ffdf83e42          39  arvalis_1               1    arvalis_1_2     0\n",
       "\n",
       "[3373 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds.to_csv('df_folds.csv')\n",
    "df_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "rTQFS81QjMfR",
    "outputId": "5fc3b4b9-66c2-4695-c82f-9d04f8a07dad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for fold_number, (train_index, val_index) in enumerate(skf.split(X=df_folds.index, y=df_folds['stratify_group'])):\n",
    "    df_folds.loc[df_folds.iloc[val_index].index, 'fold'] = fold_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "or8mSwLNkeOt",
    "outputId": "1c6f11aa-055f-4865-92c6-798122baded8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox_count</th>\n",
       "      <th>source</th>\n",
       "      <th>brightness_bin</th>\n",
       "      <th>stratify_group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00333207f</th>\n",
       "      <td>55</td>\n",
       "      <td>arvalis_1</td>\n",
       "      <td>2</td>\n",
       "      <td>arvalis_1_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005b0d8bb</th>\n",
       "      <td>20</td>\n",
       "      <td>usask_1</td>\n",
       "      <td>1</td>\n",
       "      <td>usask_1_1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006a994f7</th>\n",
       "      <td>25</td>\n",
       "      <td>inrae_1</td>\n",
       "      <td>1</td>\n",
       "      <td>inrae_1_1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00764ad5d</th>\n",
       "      <td>41</td>\n",
       "      <td>inrae_1</td>\n",
       "      <td>1</td>\n",
       "      <td>inrae_1_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00b5fefed</th>\n",
       "      <td>25</td>\n",
       "      <td>arvalis_3</td>\n",
       "      <td>0</td>\n",
       "      <td>arvalis_3_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bbox_count     source  brightness_bin stratify_group  fold\n",
       "image_id                                                             \n",
       "00333207f          55  arvalis_1               2    arvalis_1_3     3\n",
       "005b0d8bb          20    usask_1               1      usask_1_1     4\n",
       "006a994f7          25    inrae_1               1      inrae_1_1     3\n",
       "00764ad5d          41    inrae_1               1      inrae_1_2     0\n",
       "00b5fefed          25  arvalis_3               0    arvalis_3_1     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_folds['stratify_group'].value_counts()\n",
    "#df_folds[df_folds['stratify_group'] == '0_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QkOxNMYdnVjm"
   },
   "source": [
    "# 水増し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D_NP7F5bnUiU"
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.RandomSizedCrop(min_max_height=(800, 800), height=1024, width=1024, p=0.5),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                     val_shift_limit=0.2, p=0.9),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                           contrast_limit=0.2, p=0.9),\n",
    "                A.RandomGamma(),\n",
    "            ],p=0.9),\n",
    "            #A.CLAHE(p=1.0),\n",
    "            A.ToGray(p=0.01),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Resize(height=512, width=512, p=1),\n",
    "            A.Cutout(num_holes=8, max_h_size=64, max_w_size=64, fill_value=0, p=0.5),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            #A.CLAHE(p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iozS5zbDneoR"
   },
   "outputs": [],
   "source": [
    "#test autmentation :TODO\n",
    "#apply_transforms(get_train_transforms(), all_train_images, n_transforms=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f0Q0_3zJs0Ay"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ot8ULFtCsXEk"
   },
   "outputs": [],
   "source": [
    "TRAIN_ROOT_PATH = '../input/raw/train'\n",
    "\n",
    "class DatasetRetriever(Dataset):\n",
    "\n",
    "    def __init__(self, marking, image_ids, transforms=None, test=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = image_ids\n",
    "        self.marking = marking\n",
    "        self.transforms = transforms\n",
    "        self.test = test\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "        \n",
    "        if self.test or random.random() > 0.5:\n",
    "            image, boxes = self.load_image_and_boxes(index)\n",
    "        elif random.random() > 0.5:\n",
    "            image, boxes = self.load_cutmix_image_and_boxes(index)\n",
    "        else:\n",
    "            image, boxes = self.load_mixup_image_and_boxes(index)\n",
    "\n",
    "        # there is only one class\n",
    "        labels = torch.ones((boxes.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "\n",
    "        if self.transforms:\n",
    "            for i in range(10):\n",
    "                sample = self.transforms(**{\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': labels\n",
    "                })\n",
    "                if len(sample['bboxes']) > 0:\n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
    "                    break\n",
    "\n",
    "        return image, target, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def load_image_and_boxes(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        records = self.marking[self.marking['image_id'] == image_id]\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        return image, boxes\n",
    "\n",
    "    def load_cutmix_image_and_boxes(self, index, imsize=1024):\n",
    "        \"\"\" \n",
    "        This implementation of cutmix author:  https://www.kaggle.com/nvnnghia \n",
    "        Refactoring and adaptation: https://www.kaggle.com/shonenkov\n",
    "        https://www.kaggle.com/shonenkov/oof-evaluation-mixup-efficientdet　のMixup #3に対応\n",
    "        \"\"\"\n",
    "\n",
    "        w, h = imsize, imsize\n",
    "        s = imsize // 2\n",
    "    \n",
    "        xc, yc = [int(random.uniform(imsize * 0.25, imsize * 0.75)) for _ in range(2)]  # center x, y\n",
    "        indexes = [index] + [random.randint(0, self.image_ids.shape[0] - 1) for _ in range(3)]\n",
    "\n",
    "        result_image = np.full((imsize, imsize, 3), 1, dtype=np.float32)\n",
    "        result_boxes = []\n",
    "\n",
    "        for i, index in enumerate(indexes):\n",
    "            image, boxes = self.load_image_and_boxes(index)\n",
    "            if i == 0:\n",
    "                x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)\n",
    "                x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)\n",
    "            elif i == 1:  # top right\n",
    "                x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc\n",
    "                x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h\n",
    "            elif i == 2:  # bottom left\n",
    "                x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)\n",
    "                x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, max(xc, w), min(y2a - y1a, h)\n",
    "            elif i == 3:  # bottom right\n",
    "                x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)\n",
    "                x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)\n",
    "            result_image[y1a:y2a, x1a:x2a] = image[y1b:y2b, x1b:x2b]\n",
    "            padw = x1a - x1b\n",
    "            padh = y1a - y1b\n",
    "\n",
    "            boxes[:, 0] += padw\n",
    "            boxes[:, 1] += padh\n",
    "            boxes[:, 2] += padw\n",
    "            boxes[:, 3] += padh\n",
    "\n",
    "            result_boxes.append(boxes)\n",
    "\n",
    "        result_boxes = np.concatenate(result_boxes, 0)\n",
    "        np.clip(result_boxes[:, 0:], 0, 2 * s, out=result_boxes[:, 0:])\n",
    "        result_boxes = result_boxes.astype(np.int32)\n",
    "        result_boxes = result_boxes[np.where((result_boxes[:,2]-result_boxes[:,0])*(result_boxes[:,3]-result_boxes[:,1]) > 0)]\n",
    "        return result_image, result_boxes\n",
    "    \n",
    "    def load_mixup_image_and_boxes(self, index, imsize=1024):\n",
    "        image, boxes = self.load_image_and_boxes(index)\n",
    "        r_image, r_boxes = self.load_image_and_boxes(random.randint(0, self.image_ids.shape[0] - 1))\n",
    "        mixup_image = (image+r_image)/2\n",
    "\n",
    "        result_image = mixup_image.copy()\n",
    "        result_boxes = np.concatenate([boxes, r_boxes], axis=0)\n",
    "        \n",
    "        return result_image, result_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vS6whXK5vSQl"
   },
   "source": [
    "# Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8P_vFwMm2qc"
   },
   "outputs": [],
   "source": [
    "#Fitter\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzOOqLPfvOrW"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'./{config.folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "        \n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_summary_loss = 10**5\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ] \n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss = self.train_one_epoch(train_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            self.save(f'{self.base_dir}/last-checkpoint.bin')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss = self.validation(validation_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_summary_loss:\n",
    "                self.best_summary_loss = summary_loss.avg\n",
    "                self.model.eval()\n",
    "                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=summary_loss.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets, image_ids) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                images = torch.stack(images)\n",
    "                batch_size = images.shape[0]\n",
    "                images = images.to(self.device).float()\n",
    "                boxes = [target['boxes'].to(self.device).float() for target in targets]\n",
    "                labels = [target['labels'].to(self.device).float() for target in targets]\n",
    "\n",
    "                loss, _, _ = self.model(images, boxes, labels)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "        return summary_loss\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets, image_ids) in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            \n",
    "            images = torch.stack(images)\n",
    "            images = images.to(self.device).float()\n",
    "            batch_size = images.shape[0]\n",
    "            boxes = [target['boxes'].to(self.device).float() for target in targets]\n",
    "            labels = [target['labels'].to(self.device).float() for target in targets]\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss, _, _ = self.model(images, boxes, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "        return summary_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_summary_loss': self.best_summary_loss,\n",
    "            'epoch': self.epoch,\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_summary_loss = checkpoint['best_summary_loss']\n",
    "        self.epoch = checkpoint['epoch'] + 1\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hORyLM9svQt0"
   },
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 8\n",
    "    batch_size = 4\n",
    "    n_epochs = 100\n",
    "    lr = 0.0002\n",
    "\n",
    "    folder = '../output/model/effdet7-cutmix-augmix'\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False  # do scheduler.step after optimizer.step\n",
    "    validation_scheduler = True  # do scheduler.step after validation stage loss\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "#     scheduler_params = dict(\n",
    "#         max_lr=0.001,\n",
    "#         epochs=n_epochs,\n",
    "#         steps_per_epoch=int(len(train_dataset) / batch_size),\n",
    "#         pct_start=0.1,\n",
    "#         anneal_strategy='cos', \n",
    "#         final_div_factor=10**5\n",
    "#     )\n",
    "    \n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=1e-8,\n",
    "        eps=1e-08\n",
    "    )\n",
    "    # --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HyBcGkdFvqCL"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "def run_training(net, train_dataset, val_dataset,):\n",
    "    device = torch.device('cuda:0')\n",
    "    net.to(device)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        sampler=RandomSampler(train_dataset),\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(val_dataset),\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "ORFFbzlNwHy2",
    "outputId": "79c91d1f-1bd6-4f80-d1d6-78ce532debea"
   },
   "outputs": [],
   "source": [
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "def get_net():\n",
    "    #config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    config = get_efficientdet_config('tf_efficientdet_d7')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    #checkpoint = torch.load('../input/efficientdet_pytorch/efficientdet_d5-ef44aea8.pth')\n",
    "    checkpoint = torch.load('../input/efficientdet_pytorch/efficientdet_d7-f05bf714.pth')\n",
    "    net.load_state_dict(checkpoint)\n",
    "    config.num_classes = 1\n",
    "    config.image_size = 512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "    return DetBenchTrain(net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image():\n",
    "    train_dataset = DatasetRetriever(\n",
    "    image_ids=df_folds[df_folds['fold'] != 0].index.values,\n",
    "    marking=marking,\n",
    "    transforms=get_train_transforms(),\n",
    "    test=False,\n",
    "    )\n",
    "\n",
    "    count = 4\n",
    "    for i in range(count):\n",
    "        image, boxes = train_dataset.load_mixup_image_and_boxes(random.randint(0, train_dataset.image_ids.shape[0] - 1))\n",
    "        print(image.shape)\n",
    "        plt.imshow(image)\n",
    "        for b in boxes:\n",
    "            for box in b.astype(int):\n",
    "                cv2.rectangle(image,(box[0], box[1]),(box[2],  box[3]),(0, 0, 1), 3)\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fold train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCII8uCtwlSd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold0: train start\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-04T05:52:02.951160\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 0, summary_loss: 1.26648, time: 798.59723\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.45221, time: 52.85736\n",
      "\n",
      "2020-08-04T06:06:20.938033\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.54849, time: 794.92035\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.41563, time: 51.23614\n",
      "\n",
      "2020-08-04T06:20:33.804550\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.52076, time: 795.56948\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.40140, time: 51.28421\n",
      "\n",
      "2020-08-04T06:34:47.217142\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.50570, time: 794.89047\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.39568, time: 51.43422\n",
      "\n",
      "2020-08-04T06:49:00.266421\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.49763, time: 794.72379\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.40456, time: 51.22286\n",
      "\n",
      "2020-08-04T07:03:12.007123\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.49103, time: 794.41077\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.40131, time: 51.27404\n",
      "\n",
      "2020-08-04T07:17:23.323455\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.48613, time: 794.26538\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.38417, time: 51.43053\n",
      "\n",
      "2020-08-04T07:31:35.661162\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.48146, time: 794.38262\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.41382, time: 51.20042\n",
      "\n",
      "2020-08-04T07:45:46.966030\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.47958, time: 795.08856\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.39313, time: 51.23108\n",
      "\n",
      "2020-08-04T07:59:59.154480\n",
      "LR: 0.0002\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.47534, time: 794.67148\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.39003, time: 51.13921\n",
      "\n",
      "2020-08-04T08:14:10.691215\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.45808, time: 794.67448\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.37682, time: 51.18250\n",
      "\n",
      "2020-08-04T08:28:23.355222\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.45089, time: 794.86803\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.37161, time: 51.19804\n",
      "\n",
      "2020-08-04T08:42:36.075176\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.45249, time: 794.39824\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.36724, time: 51.25624\n",
      "\n",
      "2020-08-04T08:56:48.237942\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.44718, time: 794.67563\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.37684, time: 51.19116\n",
      "\n",
      "2020-08-04T09:10:59.963018\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.44602, time: 794.67064\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.38272, time: 51.23033\n",
      "\n",
      "2020-08-04T09:25:11.616132\n",
      "LR: 0.0001\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.44815, time: 794.98216\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.38300, time: 51.23778\n",
      "\n",
      "2020-08-04T09:39:23.593198\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.43455, time: 794.76514\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.36692, time: 51.39233\n",
      "\n",
      "2020-08-04T09:53:36.425304\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.43573, time: 794.91435\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.36322, time: 51.30778\n",
      "\n",
      "2020-08-04T10:07:49.102658\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.43218, time: 794.75272\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.36028, time: 51.29848\n",
      "\n",
      "2020-08-04T10:22:01.894505\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.43108, time: 794.60464\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.37515, time: 51.22736\n",
      "\n",
      "2020-08-04T10:36:13.457230\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.42982, time: 793.78116\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.36673, time: 51.35630\n",
      "\n",
      "2020-08-04T10:50:24.384755\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.42910, time: 794.43077\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.35947, time: 51.10956\n",
      "\n",
      "2020-08-04T11:04:36.560221\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.43061, time: 794.26039\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.36035, time: 51.34473\n",
      "\n",
      "2020-08-04T11:18:47.932533\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.42978, time: 794.14105\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.37370, time: 51.29085\n",
      "\n",
      "2020-08-04T11:32:59.095791\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.42726, time: 793.39347\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.35905, time: 51.20889\n",
      "\n",
      "2020-08-04T11:47:10.266729\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.42286, time: 793.72267\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.36808, time: 51.35474\n",
      "\n",
      "2020-08-04T12:01:21.095632\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.42527, time: 793.69977\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.36967, time: 51.14460\n",
      "\n",
      "2020-08-04T12:15:31.799483\n",
      "LR: 5e-05\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.42143, time: 793.08864\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.35948, time: 51.18496\n",
      "\n",
      "2020-08-04T12:29:41.823795\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.42194, time: 793.81387\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.35895, time: 51.33628\n",
      "\n",
      "2020-08-04T12:43:53.774873\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.42146, time: 794.05104\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.38066, time: 51.27565\n",
      "\n",
      "2020-08-04T12:58:04.716658\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 30, summary_loss: 0.41883, time: 794.46362\n",
      "[RESULT]: Val. Epoch: 30, summary_loss: 0.36614, time: 51.12903\n",
      "\n",
      "2020-08-04T13:12:15.974488\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 31, summary_loss: 0.41472, time: 794.07580\n",
      "[RESULT]: Val. Epoch: 31, summary_loss: 0.35643, time: 51.37053\n",
      "\n",
      "2020-08-04T13:26:32.827082\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 32, summary_loss: 0.41649, time: 794.22488\n",
      "[RESULT]: Val. Epoch: 32, summary_loss: 0.37182, time: 51.22604\n",
      "\n",
      "2020-08-04T13:40:44.070536\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 33, summary_loss: 0.41480, time: 793.96614\n",
      "[RESULT]: Val. Epoch: 33, summary_loss: 0.36595, time: 51.15960\n",
      "\n",
      "2020-08-04T13:54:54.901017\n",
      "LR: 2.5e-05\n",
      "[RESULT]: Train. Epoch: 34, summary_loss: 0.41587, time: 793.55933\n",
      "[RESULT]: Val. Epoch: 34, summary_loss: 0.38851, time: 51.28295\n",
      "\n",
      "2020-08-04T14:09:05.444839\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 35, summary_loss: 0.41217, time: 793.99344\n",
      "[RESULT]: Val. Epoch: 35, summary_loss: 0.38430, time: 51.28768\n",
      "\n",
      "2020-08-04T14:23:16.394687\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 36, summary_loss: 0.41336, time: 794.23232\n",
      "[RESULT]: Val. Epoch: 36, summary_loss: 0.36134, time: 51.17758\n",
      "\n",
      "2020-08-04T14:37:27.587005\n",
      "LR: 1.25e-05\n",
      "[RESULT]: Train. Epoch: 37, summary_loss: 0.41004, time: 794.08363\n",
      "[RESULT]: Val. Epoch: 37, summary_loss: 0.36898, time: 51.40856\n",
      "\n",
      "2020-08-04T14:51:38.857487\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 38, summary_loss: 0.40999, time: 794.62692\n",
      "[RESULT]: Val. Epoch: 38, summary_loss: 0.36208, time: 51.23045\n",
      "\n",
      "2020-08-04T15:05:50.343555\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 39, summary_loss: 0.41036, time: 793.91662\n",
      "[RESULT]: Val. Epoch: 39, summary_loss: 0.36937, time: 51.24612\n",
      "\n",
      "2020-08-04T15:20:01.283046\n",
      "LR: 6.25e-06\n",
      "[RESULT]: Train. Epoch: 40, summary_loss: 0.40890, time: 793.59249\n",
      "[RESULT]: Val. Epoch: 40, summary_loss: 0.36152, time: 51.34176\n",
      "\n",
      "2020-08-04T15:34:12.001234\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 41, summary_loss: 0.41218, time: 794.12967\n",
      "[RESULT]: Val. Epoch: 41, summary_loss: 0.36561, time: 51.31447\n",
      "\n",
      "2020-08-04T15:48:23.216839\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 42, summary_loss: 0.40864, time: 795.36930\n",
      "[RESULT]: Val. Epoch: 42, summary_loss: 0.36651, time: 51.20282\n",
      "\n",
      "2020-08-04T16:02:35.567676\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 43, summary_loss: 0.40733, time: 795.37797\n",
      "[RESULT]: Val. Epoch: 43, summary_loss: 0.35586, time: 51.34796\n",
      "\n",
      "2020-08-04T16:16:48.965083\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 44, summary_loss: 0.41005, time: 794.79512\n",
      "[RESULT]: Val. Epoch: 44, summary_loss: 0.36709, time: 51.35761\n",
      "\n",
      "2020-08-04T16:31:00.845443\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 45, summary_loss: 0.40988, time: 794.71050\n",
      "[RESULT]: Val. Epoch: 45, summary_loss: 0.36084, time: 51.22426\n",
      "\n",
      "2020-08-04T16:45:12.538057\n",
      "LR: 3.125e-06\n",
      "[RESULT]: Train. Epoch: 46, summary_loss: 0.40791, time: 794.42094\n",
      "[RESULT]: Val. Epoch: 46, summary_loss: 0.36015, time: 51.15356\n",
      "\n",
      "2020-08-04T16:59:23.893822\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 47, summary_loss: 0.41078, time: 794.57578\n",
      "[RESULT]: Val. Epoch: 47, summary_loss: 0.36670, time: 51.25399\n",
      "\n",
      "2020-08-04T17:13:35.512301\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 48, summary_loss: 0.40535, time: 794.72930\n",
      "[RESULT]: Val. Epoch: 48, summary_loss: 0.35849, time: 51.41701\n",
      "\n",
      "2020-08-04T17:27:47.439792\n",
      "LR: 1.5625e-06\n",
      "[RESULT]: Train. Epoch: 49, summary_loss: 0.40680, time: 794.65540\n",
      "[RESULT]: Val. Epoch: 49, summary_loss: 0.35670, time: 51.46175\n",
      "\n",
      "2020-08-04T17:41:59.157634\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 50, summary_loss: 0.40843, time: 794.17741\n",
      "[RESULT]: Val. Epoch: 50, summary_loss: 0.36735, time: 51.30510\n",
      "\n",
      "2020-08-04T17:56:10.467547\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 51, summary_loss: 0.40932, time: 794.38716\n",
      "[RESULT]: Val. Epoch: 51, summary_loss: 0.36663, time: 51.16166\n",
      "\n",
      "2020-08-04T18:10:21.821884\n",
      "LR: 7.8125e-07\n",
      "[RESULT]: Train. Epoch: 52, summary_loss: 0.40650, time: 796.42545\n",
      "[RESULT]: Val. Epoch: 52, summary_loss: 0.35830, time: 51.31709\n",
      "\n",
      "2020-08-04T18:24:35.342945\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 53, summary_loss: 0.40743, time: 794.03333\n",
      "[RESULT]: Val. Epoch: 53, summary_loss: 0.36624, time: 51.25804\n",
      "\n",
      "2020-08-04T18:38:46.410784\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 54, summary_loss: 0.40829, time: 794.50436\n",
      "[RESULT]: Val. Epoch: 54, summary_loss: 0.36667, time: 51.42859\n",
      "\n",
      "2020-08-04T18:52:58.151327\n",
      "LR: 3.90625e-07\n",
      "[RESULT]: Train. Epoch: 55, summary_loss: 0.40528, time: 797.98615\n",
      "[RESULT]: Val. Epoch: 55, summary_loss: 0.36710, time: 51.72490\n",
      "\n",
      "2020-08-04T19:07:13.654388\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 56, summary_loss: 0.40877, time: 801.00919\n",
      "[RESULT]: Val. Epoch: 56, summary_loss: 0.36730, time: 51.58452\n",
      "\n",
      "2020-08-04T19:21:32.189604\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 57, summary_loss: 0.40702, time: 800.76779\n",
      "[RESULT]: Val. Epoch: 57, summary_loss: 0.38771, time: 51.44522\n",
      "\n",
      "2020-08-04T19:35:50.212363\n",
      "LR: 1.953125e-07\n",
      "[RESULT]: Train. Epoch: 58, summary_loss: 0.40638, time: 801.91578\n",
      "[RESULT]: Val. Epoch: 58, summary_loss: 0.38740, time: 51.55191\n",
      "\n",
      "2020-08-04T19:50:09.365048\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 59, summary_loss: 0.40872, time: 799.47614\n",
      "[RESULT]: Val. Epoch: 59, summary_loss: 0.36532, time: 51.36715\n",
      "\n",
      "2020-08-04T20:04:25.988089\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 60, summary_loss: 0.40710, time: 801.19270\n",
      "[RESULT]: Val. Epoch: 60, summary_loss: 0.35849, time: 51.45808\n",
      "\n",
      "2020-08-04T20:18:44.314656\n",
      "LR: 9.765625e-08\n",
      "[RESULT]: Train. Epoch: 61, summary_loss: 0.40902, time: 800.29636\n",
      "[RESULT]: Val. Epoch: 61, summary_loss: 0.36825, time: 51.41572\n",
      "\n",
      "2020-08-04T20:33:01.825512\n",
      "LR: 4.8828125e-08\n",
      "[RESULT]: Train. Epoch: 62, summary_loss: 0.41081, time: 801.16918\n",
      "[RESULT]: Val. Epoch: 62, summary_loss: 0.36286, time: 51.53342\n",
      "\n",
      "2020-08-04T20:47:20.447762\n",
      "LR: 4.8828125e-08\n",
      "[RESULT]: Train. Epoch: 63, summary_loss: 0.40506, time: 800.46361\n",
      "[RESULT]: Val. Epoch: 63, summary_loss: 0.37695, time: 51.53909\n",
      "\n",
      "2020-08-04T21:01:38.267241\n",
      "LR: 4.8828125e-08\n",
      "[RESULT]: Train. Epoch: 64, summary_loss: 0.40678, time: 800.64189\n",
      "[RESULT]: Val. Epoch: 64, summary_loss: 0.36240, time: 51.55470\n",
      "\n",
      "2020-08-04T21:15:56.115080\n",
      "LR: 2.44140625e-08\n",
      "[RESULT]: Train. Epoch: 65, summary_loss: 0.40568, time: 799.36175\n",
      "[RESULT]: Val. Epoch: 65, summary_loss: 0.36160, time: 51.60496\n",
      "\n",
      "2020-08-04T21:30:12.828792\n",
      "LR: 2.44140625e-08\n",
      "[RESULT]: Train. Epoch: 66, summary_loss: 0.41095, time: 799.81046\n",
      "[RESULT]: Val. Epoch: 66, summary_loss: 0.36273, time: 51.57816\n",
      "\n",
      "2020-08-04T21:44:29.992732\n",
      "LR: 2.44140625e-08\n",
      "[RESULT]: Train. Epoch: 67, summary_loss: 0.40603, time: 801.40434\n",
      "[RESULT]: Val. Epoch: 67, summary_loss: 0.36300, time: 51.46291\n",
      "\n",
      "2020-08-04T21:58:48.551537\n",
      "LR: 1.220703125e-08\n",
      "Train Step 368/674, summary_loss: 0.41266, time: 436.66705\r"
     ]
    }
   ],
   "source": [
    "for fold_number in range(N_SPLITS):\n",
    "    print(f'fold{fold_number}: train start')\n",
    "    \n",
    "    train_dataset = DatasetRetriever(\n",
    "        image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n",
    "        marking=marking,\n",
    "        transforms=get_train_transforms(),\n",
    "        test=False,\n",
    "    )\n",
    "    val_dataset = DatasetRetriever(\n",
    "        image_ids=df_folds[df_folds['fold'] == fold_number].index.values,\n",
    "        marking=marking,\n",
    "        transforms=get_valid_transforms(),\n",
    "        test=True,\n",
    "    )\n",
    "    # train model\n",
    "    net = get_net()\n",
    "    TrainGlobalConfig.folder = f'../output/model/effdet7-cutmix-augmix/fold{fold_number}'\n",
    "    run_training(net, train_dataset, val_dataset)\n",
    "\n",
    "#     image, target, image_id = train_dataset[1]\n",
    "#     boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
    "\n",
    "#     numpy_image = image.permute(1,2,0).cpu().numpy()\n",
    "\n",
    "#     fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "#     for box in boxes:\n",
    "#         cv2.rectangle(numpy_image, (box[1], box[0]), (box[3],  box[2]), (0, 1, 0), 2)\n",
    "\n",
    "#     ax.set_axis_off()\n",
    "#     ax.imshow(numpy_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GlobalWheatDetection EDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
